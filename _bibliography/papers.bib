---
---

@string{aps = {American Physical Society,}}
@string{micro22 = {American Physical Society,}}

@INPROCEEDINGS{cronus,
  author={Jiang, Jianyu and Qi, Ji and Shen, Tianxiang and Chen, Xusheng and Zhao, Shixiong and Wang, Sen and Chen, Li and Zhang, Gong and Luo, Xiapu and Cui, Heming},
  booktitle={2022 55th IEEE/ACM International Symposium on Microarchitecture (MICRO)}, 
  title={CRONUS: Fault-isolated, Secure and High-performance Heterogeneous Computing for Trusted Execution Environment}, 
  year={2022},
  volume={},
  number={},
  pages={124-143},
  doi={10.1109/MICRO56248.2022.00019},
  selected={true}
}
@inproceedings{10.1145/3545948.3545972,
author = {Jiang, Jianyu and Soriente, Claudio and Karame, Ghassan},
title = {On the Challenges of Detecting Side-Channel Attacks in SGX},
year = {2022},
isbn = {9781450397049},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://dl.acm.org/doi/10.1145/3545948.3545972},
doi = {10.1145/3545948.3545972},
abstract = {Existing tools to detect side-channel attacks on Intel SGX are grounded on the observation that attacks affect the performance of the victim application. As such, all detection tools monitor the potential victim and raise an alarm if the witnessed performance (in terms of runtime, enclave interruptions, cache misses, etc.) is out of the ordinary. In this paper, we show that monitoring the performance of enclaves to detect side-channel attacks may not be effective. Our core intuition is that all monitoring tools are geared towards an adversary that interferes with the victim’s execution in order to extract the most number of secret bits (e.g., the entire secret) in one or few runs. They cannot, however, detect an adversary that leaks smaller portions of the secret—as small as a single bit—at each execution of the victim. In particular, by minimizing the information leaked at each run, the impact of any side-channel attack on the application’s performance is significantly lowered—ensuring that the detection tool does not detect an attack. By repeating the attack multiple times, each time on a different part of the secret, the adversary can recover the whole secret and remain undetected. Based on this intuition, we adapt known attacks leveraging page-tables and L3 cache to bypass existing detection mechanisms. We show experimentally how an attacker can successfully exfiltrate the secret key used in an enclave running various cryptographic routines of libgcrypt. Beyond cryptographic libraries, we also show how to compromise the predictions of enclaves running decision-tree routines of OpenCV. Our evaluation results suggest that performance-based detection tools do not deter side-channel attacks on SGX enclaves and that effective detection mechanisms are yet to be designed.},
booktitle = {Proceedings of the 25th International Symposium on Research in Attacks, Intrusions and Defenses},
pages = {86-98},
numpages = {13},
keywords = {Intel Software Guard eXtensions (SGX), Side-channel Attacks},
location = {Limassol, Cyprus},
series = {RAID '22},
selected={true}
}

@inproceedings{uranus,
author = {Jiang, Jianyu and Chen, Xusheng and Li, TszOn and Wang, Cheng and Shen, Tianxiang and Zhao, Shixiong and Cui, Heming and Wang, Cho-Li and Zhang, Fengwei},
title = {Uranus: Simple, Efficient SGX Programming and Its Applications},
year = {2020},
isbn = {9781450367509},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://dl.acm.org/doi/10.1145/3320269.3384763},
doi = {10.1145/3320269.3384763},
abstract = {Applications written in Java have strengths to tackle diverse threats in public clouds, but these applications are still prone to privileged attacks when processing plaintext data. Intel SGX is powerful to tackle these attacks, and traditional SGX systems rewrite a Java application's sensitive functions, which process plaintext data, using C/C++ SGX API. Although this code-rewrite approach achieves good efficiency and a small TCB, it requires SGX expert knowledge and can be tedious and error-prone. To tackle the limitations of rewriting Java to C/C++, recent SGX systems propose a code-reuse approach, which runs a default JVM in an SGX enclave to execute the sensitive Java functions. However, both recent study and this paper find that running a default JVM in enclaves incurs two major vulnerabilities, Iago attacks, and control flow leakage of sensitive functions, due to the usage of OS features in JVM. In this paper, Uranus creates easy-to-use Java programming abstractions for application developers to annotate sensitive functions, and Uranus automatically runs these functions in SGX at runtime. Uranus effectively tackles the two major vulnerabilities in the code-reuse approach by presenting two new protocols: 1) a Java bytecode attestation protocol for dynamically loaded functions; and 2) an OS-decoupled, efficient GC protocol optimized for data-handling applications running in enclaves. We implemented Uranus in Linux and applied it to two diverse data-handling applications: Spark and ZooKeeper. Evaluation shows that: 1) Uranus achieves the same security guarantees as two relevant SGX systems for these two applications with only a few annotations; 2) Uranus has reasonable performance overhead compared to the native, insecure applications; and 3) Uranus defends against privileged attacks. Uranus source code and evaluation results are released on https://github.com/hku-systems/uranus.},
booktitle = {Proceedings of the 15th ACM Asia Conference on Computer and Communications Security},
pages = {826-–840},
numpages = {15},
keywords = {Java, garbage collector (GC), side-channel, SGX, big-data, JVM, data-handling, TEE, IAGO attack, spark, zookeeper, type-safety},
location = {Taipei, Taiwan},
series = {ASIA CCS '20},
selected={true}
}

@inproceedings {soter,
author = {Tianxiang Shen and Ji Qi and Jianyu Jiang and Xian Wang and Siyuan Wen and Xusheng Chen and Shixiong Zhao and Sen Wang and Li Chen and Xiapu Luo and Fengwei Zhang and Heming Cui},
title = {{SOTER}: Guarding Black-box Inference for General Neural Networks at the Edge},
booktitle = {2022 USENIX Annual Technical Conference (USENIX ATC 22)},
year = {2022},
isbn = {978-1-939133-29-68},
address = {Carlsbad, CA},
pages = {723--738},
abstract={The prosperity of AI and edge computing has pushed more and more well-trained DNN models to be deployed on third-party edge devices to compose mission-critical applications. This necessitates protecting model confidentiality at untrusted devices, and using a co-located accelerator (e.g., GPU) to speed up model inference locally. Recently, the community has sought to improve the security with CPU trusted execution environments (TEE). However, existing solutions either run an entire model in TEE, suffering from extremely high inference latency, or take a partition-based approach to handcraft partial model via parameter obfuscation techniques to run on an untrusted GPU, achieving lower inference latency at the expense of both the integrity of partitioned computations outside TEE and accuracy of obfuscated parameters. We propose SOTER, the first system that can achieve model confidentiality, integrity, low inference latency and high accuracy in the partition-based approach. Our key observation is that there is often an \textit{associativity} property among many inference operators in DNN models. Therefore, SOTER automatically transforms a major fraction of associative operators into \textit{parameter-morphed}, thus \textit{confidentiality-preserved} operators to execute on untrusted GPU, and fully restores the execution results to accurate results with associativity in TEE. Based on these steps, SOTER further designs an \textit{oblivious fingerprinting} technique to safely detect integrity breaches of morphed operators outside TEE to ensure correct executions of inferences. Experimental results on six prevalent models in the three most popular categories show that, even with stronger model protection, SOTER achieves comparable performance with partition-based baselines while retaining the same high accuracy as insecure inference.},
url = {https://www.usenix.org/conference/atc22/presentation/shen},
publisher = {USENIX Association},
month = jul,
selected={true}
}
@inproceedings{bidl,
  author = {Qi, Ji and Chen, Xusheng and Jiang, Yunpeng and Jiang, Jianyu and Shen, Tianxiang and Zhao, Shixiong and Wang, Sen and Zhang, Gong and Chen, Li and Au, Man Ho and Cui, Heming},
  title = {Bidl: A High-Throughput, Low-Latency Permissioned Blockchain Framework for Datacenter Networks},
  year = {2021},
  isbn = {9781450387095},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://dl.acm.org/10.1145/3477132.3483574},
  doi = {10.1145/3477132.3483574},
  abstract = {A permissioned blockchain framework typically runs an efficient Byzantine consensus protocol and is attractive to deploy fast trading applications among a large number of mutually untrusted participants (e.g., companies). Unfortunately, all existing permissioned blockchain frameworks adopt sequential workflows for invoking the consensus protocol and executing applications' transactions, making the performance of these applications much lower than deploying them in traditional systems (e.g., in-datacenter stock exchange).We propose Bidl, the first permissioned blockchain framework highly optimized for datacenter networks. We leverage the network ordering in such networks to create a shepherded parallel workflow, which carries a sequencer to parallelize the consensus protocol and transaction execution speculatively. However, the presence of malicious participants (e.g., a malicious sequencer) can easily perturb the parallel workflow to greatly degrade Bidl's performance. To achieve stable high performance, Bidl efficiently shepherds all participants by detecting their misbehaviors, and performs denylist-based view changes to replace or deny malicious participants. Compared with three fast permissioned blockchain frameworks, Bidl's parallel workflow reduces applications' latency by up to 72.7% and improves their throughput by up to 4.3x in the presence of malicious participants. Bidl is suitable to be integrated with traditional stock exchange systems. Bidl's code is released on github.com/hku-systems/bidl.},
  booktitle = {Proceedings of the ACM SIGOPS 28th Symposium on Operating Systems Principles},
  pages = {18--34},
  numpages = {17},
  keywords = {high-performance blockchain workflows, permissioned blockchains, byzantine fault tolerance},
  location = {Virtual Event, Germany},
  series = {SOSP '21},
  selected={true}
}
@inproceedings{apus,
author = {Wang, Cheng and Jiang, Jianyu and Chen, Xusheng and Yi, Ning and Cui, Heming},
title = {APUS: Fast and Scalable Paxos on RDMA},
year = {2017},
isbn = {9781450350280},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://dl.acm.org/doi/10.1145/3127479.3128609},
doi = {10.1145/3127479.3128609},
abstract = {State machine replication (SMR) uses Paxos to enforce the same inputs for a program (e.g., Redis) replicated on a number of hosts, tolerating various types of failures. Unfortunately, traditional Paxos protocols incur prohibitive performance overhead on server programs due to their high consensus latency on TCP/IP. Worse, the consensus latency of extant Paxos protocols increases drastically when more concurrent client connections or hosts are added. This paper presents APUS, the first RDMA-based Paxos protocol that aims to be fast and scalable to client connections and hosts. APUS intercepts inbound socket calls of an unmodified server program, assigns a total order for all input requests, and uses fast RDMA primitives to replicate these requests concurrently.We evaluated APUS on nine widely-used server programs (e.g., Redis and MySQL). APUS incurred a mean overhead of 4.3% in response time and 4.2% in throughput. We integrated APUS with an SMR system Calvin. Our Calvin-APUS integration was 8.2X faster than the extant Calvin-ZooKeeper integration. The consensus latency of APUS outperformed an RDMA-based consensus protocol by 4.9X. APUS source code and raw results are released on github.com/hku-systems/apus.},
booktitle = {Proceedings of the 2017 Symposium on Cloud Computing},
pages = {94--107},
numpages = {14},
keywords = {fault tolerance, software reliability, remote direct memory access, state machine replication},
location = {Santa Clara, California},
series = {SoCC '17}
}

@article{eges,
author = {Chen, Xusheng and Zhao, Shixiong and Qi, Ji and Jiang, Jianyu and Song, Haoze and Wang, Cheng and On Li, Tsz and Hubert Chan, T-H. and Zhang, Fengwei and Luo, Xiapu and Wang, Sen and Zhang, Gong and Cui, Heming},
title = {Efficient and DoS-Resistant Consensus for Permissioned Blockchains},
year = {2022},
issue_date = {December 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {3},
issn = {0163-5999},
url = {https://dl.acm.org/doi/10.1145/3529113.3529134},
doi = {10.1145/3529113.3529134},
abstract = {Existing permissioned blockchain systems designate a fixed and explicit group of committee nodes to run a consensus protocol that confirms the same sequence of blocks among all nodes. Unfortunately, when such a system runs on a large scale on the Internet, these explicit committee nodes can be easily turned down by denialof- service (DoS) or network partition attacks. Although recent studies proposed scalable BFT protocols that run on a larger number of committee nodes, these protocols' efficiency drops dramatically when only a small number of nodes are attacked.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = {mar},
pages = {61--62},
numpages = {2}
}

@inproceedings{dast,
author = {Chen, Xusheng and Song, Haoze and Jiang, Jianyu and Ruan, Chaoyi and Li, Cheng and Wang, Sen and Zhang, Gong and Cheng, Reynold and Cui, Heming},
title = {Achieving Low Tail-Latency and High Scalability for Serializable Transactions in Edge Computing},
year = {2021},
isbn = {9781450383349},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://dl.acm.org/doi/10.1145/3447786.3456238},
doi = {10.1145/3447786.3456238},
abstract = {A distributed database utilizing the wide-spread edge computing servers to provide low-latency data access with the serializability guarantee is highly desirable for emerging edge computing applications. In an edge database, nodes are divided into regions, and a transaction can be categorized as intra-region (IRT) or cross-region (CRT) based on whether it accesses data in different regions. In addition to serializability, we insist that a practical edge database should provide low tail latency for both IRTs and CRTs, and such low latency must be scalable to a large number of regions. Unfortunately, none of existing geo-replicated serializable databases or edge databases can meet such requirements.In this paper, we present Dast (Decentralized Anticipate and STretch), the first edge database that can meet the stringent performance requirements with serializability. Our key idea is to order transactions by anticipating when they are ready to execute: Dast binds an IRT to the latest timestamp and binds a CRT to a future timestamp to avoid the coordination of CRTs blocking IRTs. Dast also carries a new stretchable clock abstraction to tolerate inaccurate anticipations and to handle cross-region data reads. Our evaluation shows that, compared to three relevant serializable databases, Dast's 99-percentile latency was 87.9%~93.2% lower for IRTs and 27.7%~70.4% lower for CRTs; Dast's low latency is scalable to a large number of regions.},
booktitle = {Proceedings of the Sixteenth European Conference on Computer Systems},
pages = {210--227},
numpages = {18},
keywords = {distributed transaction, tail-latency, scalability, edge computing},
location = {Online Event, United Kingdom},
series = {EuroSys '21}
}

@INPROCEEDINGS {upa,
author = {Tsz On Li and Jianyu Jiang and Ji Qi and Chi Chiu So and Jiacheng Ma and Xusheng Chen and Tianxiang Shen and Heming Cui and Yuexuan Wang and Peng Wang},
booktitle = {2020 50th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN)},
title = {UPA: An Automated, Accurate and Efficient Differentially Private Big-Data Mining System},
year = {2020},
volume = {},
issn = {1530-0889},
pages = {515-527},
abstract = {In the era of big-data, individuals and institutions store their sensitive data on clouds, and these data are often analyzed and computed by MapReduce frameworks (e.g., Spark). However, releasing the computation result on these data may leak privacy. Differential Privacy (DP) is a powerful method to preserve the privacy of an individual data record from a computation result. Given an input dataset and a query, DP typically perturbs an output value with noise proportional to sensitivity, the greatest change on an output value when a record is added to or removed from the input dataset. Unfortunately, directly computing the sensitivity value for a query and an input dataset is computationally infeasible, because it requires adding or removing every record from the dataset and repeatedly running the same query on the dataset: a dataset of one million input records requires running the same query for more than one million times. This paper presents UPA, the first automated, accurate, and efficient sensitivity inferring approach for big-data mining applications. Our key observation is that MapReduce operators often have commutative and associative properties in order to enable parallelism and fault tolerance among computers. Therefore, UPA can greatly reduce the repeated computations at runtime while computing a precise sensitivity value automatically for general big-data queries. We compared UPA with FLEX, the most relevant work that does static analysis on queries to infer sensitivity values. Based on an extensive evaluation on nine diverse Spark queries, UPA supports all the nine evaluated queries, while FLEX supports only five of the nine queries. For the five queries which both UPA and FLEX can support, UPA enforces DP with five orders of magnitude more accurate sensitivity values than FLEX. UPA has reasonable performance overhead compared to native Spark. UPA&#x27;s source code is available on https://github.com/hku-systems/UPA.},
keywords = {sensitivity;flexible printed circuits;sparks;static analysis},
doi = {10.1109/DSN48063.2020.00064},
url = {https://doi.ieeecomputersociety.org/10.1109/DSN48063.2020.00064},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {jul}
}



@ARTICLE{daenet,
  author={Shen, Tianxiang and Jiang, Jianyu and Jiang, Yunpeng and Chen, Xusheng and Qi, Ji and Zhao, Shixiong and Zhang, Fengwei and Luo, Xiapu and Cui, Heming},
  journal={IEEE Transactions on Dependable and Secure Computing}, 
  title={DAENet: Making Strong Anonymity Scale in a Fully Decentralized Network}, 
  abstract={Traditional anonymous networks (e.g., Tor) are vulnerable to traffic analysis attacks that monitor the whole network traffic to determine which users are communicating. To preserve user anonymity against traffic analysis attacks, the emerging mix networks mess up the order of packets through a set of centralized and explicit shuffling nodes. However, this centralized design of mix networks is insecure against targeted DoS attacks that can completely block these shuffling nodes. In this article, we present DAENet , an efficient mix network that resists both targeted DoS attacks and traffic analysis attacks with a new abstraction called Stealthy Peer-to-Peer (P2P) Network . The stealthy P2P network effectively hides the shuffling nodes used in a routing path into the whole network, such that adversaries cannot distinguish specific shuffling nodes and conduct targeted DoS attacks to block these nodes. In addition, to handle traffic analysis attacks, we leverage the confidentiality and integrity protection of Intel SGX to ensure trustworthy packet shuffles at each distributed host and use multiple routing paths to prevent adversaries from tracking and revealing user identities. We show that our system is scalable with moderate latency (2.2s) when running in a cluster of 10,000 participants and is robust in the case of machine failures, making it an attractive new design for decentralized anonymous communication. DAENet ’s code is released on https://github.com/hku-systems/DAENet .},
  year={2022},
  volume={19},
  number={4},
  url={https://ieeexplore-ieee-org.eproxy.lib.hku.hk/document/9328493},
  pages={2286-2303},
  doi={10.1109/TDSC.2021.3052831},
  selected={true}
}

@inproceedings{kakute,
author = {Jiang, Jianyu and Zhao, Shixiong and Alsayed, Danish and Wang, Yuexuan and Cui, Heming and Liang, Feng and Gu, Zhaoquan},
title = {Kakute: A Precise, Unified Information Flow Analysis System for Big-Data Security},
year = {2017},
isbn = {9781450353458},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://dl.acm.org/doi/10.1145/3134600.3134607},
doi = {10.1145/3134600.3134607},
abstract = {Big-data frameworks (e.g., Spark) enable computations on tremendous data records generated by third parties, causing various security and reliability problems such as information leakage and programming bugs. Existing systems for big-data security (e.g., Titian) track data transformations in a record level, so they are imprecise and too coarse-grained for these problems. For instance, when we ran Titian to drill down input records that produced a buggy output record, Titian reported 3 to 9 orders of magnitude more input records than the actual ones. Information Flow Tracking (IFT) is a conventional approach for precise information control. However, extant IFT systems are neither efficient nor complete for big-data frameworks, because theses frameworks are data-intensive, and data flowing across hosts is often ignored by IFT.This paper presents Kakute, the first precise, fine-grained information flow analysis system for big-data. Our insight on making IFT efficient is that most fields in a data record often have the same IFT tags, and we present two new efficient techniques called Reference Propagation and Tag Sharing. In addition, we design an efficient, complete cross-host information flow propagation approach. Evaluation on seven diverse big-data programs (e.g., WordCount) shows that Kakute had merely 32.3% overhead on average even when fine-grained information control was enabled. Compared with Titian, Kakute precisely drilled down the actual bug inducing input records, a huge reduction of 3 to 9 orders of magnitude. Kakute's performance overhead is comparable with Titian. Furthermore, Kakute effectively detected 13 real-world security and reliability bugs in 4 diverse problems, including information leakage, data provenance, programming and performance bugs. Kakute's source code and results are available on https://github.com/hku-systems/kakute.},
booktitle = {Proceedings of the 33rd Annual Computer Security Applications Conference},
pages = {79--90},
numpages = {12},
keywords = {Data-intensive Scalable Computing System, Information Flow Tracking, Big-data},
location = {Orlando, FL, USA},
series = {ACSAC '17},
selected={true}
}

@ARTICLE{vpipe,
  author={Zhao, Shixiong and Li, Fanxin and Chen, Xusheng and Guan, Xiuxian and Jiang, Jianyu and Huang, Dong and Qing, Yuhao and Wang, Sen and Wang, Peng and Zhang, Gong and Li, Cheng and Luo, Ping and Cui, Heming},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={vPipe: A Virtualized Acceleration System for Achieving Efficient and Scalable Pipeline Parallel DNN Training}, 
  year={2022},
  abstract={The increasing computational complexity of DNNs achieved unprecedented successes in various areas such as machine vision and natural language processing (NLP), e.g., the recent advanced Transformer has billions of parameters. However, as large-scale DNNs significantly exceed GPU’s physical memory limit, they cannot be trained by conventional methods such as data parallelism. Pipeline parallelism that partitions a large DNN into small subnets and trains them on different GPUs is a plausible solution. Unfortunately, the layer partitioning and memory management in existing pipeline parallel systems are fixed during training, making them easily impeded by out-of-memory errors and the GPU under-utilization. These drawbacks amplify when performing neural architecture search (NAS) such as the evolved Transformer, where different network architectures of Transformer needed to be trained repeatedly. vPipe is the first system that transparently provides dynamic layer partitioning and memory management for pipeline parallelism. vPipe has two unique contributions, including (1) an online algorithm for searching a near-optimal layer partitioning and memory management plan, and (2) a live layer migration protocol for re-balancing the layer distribution across a training pipeline. vPipe improved the training throughput of two notable baselines (Pipedream and GPipe) by 61.4-463.4 percent and 24.8-291.3 percent on various large DNNs and training settings.},
  url={https://ieeexplore-ieee-org.eproxy.lib.hku.hk/document/9472938},
  volume={33},
  number={3},
  pages={489-506},
  doi={10.1109/TPDS.2021.3094364}
}
